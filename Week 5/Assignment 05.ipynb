{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring and Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment 5\n",
    "\n",
    "For this assignment and future assignments, assume that you are the owner of a small but growing retail business, *Datums R Us*. Your store sells technology, tools, and clothing for the discerning data scientist. You currently have stores in the following five locations. \n",
    "\n",
    "- Bellevue, Nebraska\n",
    "- Columbus, Ohio\n",
    "- Denver, Colorado\n",
    "- San Francisco, California\n",
    "- Baltimore, Maryland\n",
    "\n",
    "You have been tasked with creating a data lake for the company using a [directory structure based on Cookiecutter Data Science recommendations](https://drivendata.github.io/cookiecutter-data-science/#directory-structure). This basic directory structure works well for small, self-contained data science projects and organizing large-scale data warehouses.\n",
    "\n",
    "```\n",
    "├── data\n",
    "│   ├── external       <- Data from third-party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling and reports.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "```\n",
    "\n",
    "You have identified the following items for initial inclusion in the data lake. \n",
    "\n",
    "**External Data Sets**\n",
    "\n",
    "- Census (Updated Yearly)\n",
    "- Weather Forecasts (Updated Daily)\n",
    "\n",
    "**Raw Data Dumps**\n",
    "\n",
    "- Sales (Updated Hourly)\n",
    "- Inventory (Updated Daily)\n",
    "- Expenses (Updated Daily)\n",
    "\n",
    "**Processed Data Sets and Reports**\n",
    "\n",
    "*Weekly*\n",
    "\n",
    "- Modeling Data Set\n",
    "\n",
    "*Monthly*\n",
    "\n",
    "- Inventory Update Request\n",
    "\n",
    "*Quarterly*\n",
    "\n",
    "- Quarterly Financial Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.1\n",
    "\n",
    "In the first part of the assignment, you will describe the directory structure for the data lake. For the most part, this directory structure will not depend on the technical details of how you store the data. You could be storing the data in a local filesystem, a distributed filesystem such as HDFS, or object storage, such as Amazon S3. \n",
    "\n",
    "You will only be creating the directory structures and not populating actual content. Real-world data lakes store data in a variety of formats including,  Apache Parquet, Google Protocol Buffers, Apache Avro, JSONL, and CSV. \n",
    "\n",
    "You will use Python's built-in [calendar library](https://docs.python.org/3/library/calendar.html), and [datetime library](https://docs.python.org/3/library/datetime.html) to work with the dates and times required for this assignment. You will use the [PurePosixPath](https://docs.python.org/3/library/pathlib.html#pathlib.PurePosixPath) class from Python's built-in [pathlib library](https://docs.python.org/3/library/pathlib.html) to represent locations on the data lake. \n",
    "\n",
    "You will generate the output directories for an entire year's worth of data starting on January 1st of this year. Unless otherwise specified, all times will be in Coordinated Universal Time (UTC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the required Python libraries and \n",
    "# sets global variables for the assignment\n",
    "import calendar\n",
    "import datetime\n",
    "from pathlib import PurePosixPath, Path\n",
    "from functools import reduce\n",
    "\n",
    "today = datetime.date.today()\n",
    "current_year = today.year\n",
    "days_in_year = 365\n",
    "\n",
    "if calendar.isleap(current_year):\n",
    "    days_in_year +=1\n",
    "\n",
    "hours_in_year = days_in_year * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Data Directory: data\n",
      "External Data Directory: data\\external\n",
      "Interim Data Directory: data\\interim\n",
      "Processed Data Directory: data\\processed\n",
      "Raw Data Directory: data\\raw\n"
     ]
    }
   ],
   "source": [
    "# Creates paths for the external, interim, processed, and raw directories\n",
    "# Use these paths when creating new paths\n",
    "\n",
    "root_data_dir = Path('data')\n",
    "external_data_dir = root_data_dir.joinpath('external')\n",
    "interim_data_dir = root_data_dir.joinpath('interim')\n",
    "processed_data_dir = root_data_dir.joinpath('processed')\n",
    "raw_data_dir = root_data_dir.joinpath('raw')\n",
    "\n",
    "print('Root Data Directory: {}'.format(root_data_dir))\n",
    "print('External Data Directory: {}'.format(external_data_dir))\n",
    "print('Interim Data Directory: {}'.format(interim_data_dir))\n",
    "print('Processed Data Directory: {}'.format(processed_data_dir))\n",
    "print('Raw Data Directory: {}'.format(raw_data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.a\n",
    "\n",
    "For the purposes of this assignment, we will be using three Census data sets as examples of external data updated yearly. These data sets are:\n",
    "\n",
    "- [American Community Survey (ACS) Summary File](https://www.census.gov/programs-surveys/acs/data/summary-file.html)\n",
    "- [American Community Survey (ACS) Public Use Microdata Sample (PUMS)]( https://www.census.gov/programs-surveys/acs/microdata.html)\n",
    "- [Tiger/Line Shapefiles](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html)\n",
    "\n",
    "If you are curious, you can find the actual data sets at the following locations: \n",
    "\n",
    "- [ACS Summary File](https://www2.census.gov/programs-surveys/acs/summary_file/)\n",
    "- [PUMS](https://www2.census.gov/programs-surveys/acs/data/pums/)\n",
    "- [Tiger](https://www2.census.gov/geo/tiger/)\n",
    "\n",
    "For this assignment, we use the following naming convention for external data sets\n",
    "\n",
    "```\n",
    "/data/external/<source>/<data-set>/<year>/\n",
    "```\n",
    "where *source* is the organization providing the data, *data-set* is the specific data set, and *year* is the year. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "│   ├── census\n",
    "│   │   ├── acs-summaryfile\n",
    "│   │   │   ├── 2015\n",
    "│   │   │   ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │   │   └── 2019\n",
    "│   │   ├── pums\n",
    "│   │   │   ├── 2015\n",
    "│   │   │   ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │   │   └── 2020\n",
    "│   │   └── tiger\n",
    "│   │       ├── 2015\n",
    "│   │       ├── 2016\n",
    "│   │   │   ...\n",
    "│   │   │   ...\n",
    "│   │       └── 2020\n",
    "│   └── nwc-wpc\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/external/census/acs-summaryfile/2015'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2016'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2017'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2018'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2019'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2020'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2021'),\n",
       " WindowsPath('data/external/census/acs-summaryfile/2022')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_summary_file_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "census_path = external_data_dir.joinpath('census')\n",
    "acs_path = census_path.joinpath('acs-summaryfile')\n",
    "\n",
    "census_path.mkdir(parents=True, exist_ok=True)\n",
    "acs_path.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "for yr in range(2015,current_year):\n",
    "    yr_temp_path = acs_path.joinpath(str(yr))\n",
    "    try:\n",
    "        yr_temp_path.mkdir()\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for yr_path in acs_path.iterdir():\n",
    "    acs_summary_file_dirs.add(yr_path)\n",
    "# Should output sorted directories from 2015 to present \n",
    "sorted(list(acs_summary_file_dirs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/external/census/pums/2015'),\n",
       " WindowsPath('data/external/census/pums/2016'),\n",
       " WindowsPath('data/external/census/pums/2017'),\n",
       " WindowsPath('data/external/census/pums/2018'),\n",
       " WindowsPath('data/external/census/pums/2019'),\n",
       " WindowsPath('data/external/census/pums/2020'),\n",
       " WindowsPath('data/external/census/pums/2021'),\n",
       " WindowsPath('data/external/census/pums/2022')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pums_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "pums_path = census_path.joinpath('pums')\n",
    "\n",
    "pums_path.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "for yr in range(2015,current_year):\n",
    "    yr_temp_path = pums_path.joinpath(str(yr))\n",
    "    try:\n",
    "        yr_temp_path.mkdir()\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for yr_path in pums_path.iterdir():\n",
    "    pums_dirs.add(yr_path)\n",
    "\n",
    "\n",
    "# Should output sorted directories from 2015 to present \n",
    "sorted(list(pums_dirs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/external/census/tiger/2015'),\n",
       " WindowsPath('data/external/census/tiger/2016'),\n",
       " WindowsPath('data/external/census/tiger/2017'),\n",
       " WindowsPath('data/external/census/tiger/2018'),\n",
       " WindowsPath('data/external/census/tiger/2019'),\n",
       " WindowsPath('data/external/census/tiger/2020'),\n",
       " WindowsPath('data/external/census/tiger/2021'),\n",
       " WindowsPath('data/external/census/tiger/2022')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger_dirs = set()\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "tiger_path = census_path.joinpath('tiger')\n",
    "\n",
    "tiger_path.mkdir(exist_ok=True)\n",
    "\n",
    "for yr in range(2015,current_year):\n",
    "    yr_temp_path = tiger_path.joinpath(str(yr))\n",
    "    try:\n",
    "        yr_temp_path.mkdir()\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "for yr_path in tiger_path.iterdir():\n",
    "    tiger_dirs.add(yr_path)\n",
    "\n",
    "\n",
    "# Should output sorted directories from 2015 to present \n",
    "sorted(list(tiger_dirs)) # Should output sorted directories from 2015 to present "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.1.d\n",
    "\n",
    "Finally, you will create directories for a daily data set based on the [National Weather Service's (NWS) Weather Prediction Center's (WPC) daily forecasts](https://www.wpc.ncep.noaa.gov/kml/kmlproducts.php). \n",
    "\n",
    "For this part, we use the following naming convention\n",
    "\n",
    "```\n",
    "/data/external/nwc-wpc/forecasts/<year>/<month>/<day>/\n",
    "```\n",
    "where *year* is the year, *month* is the two-digit month, and *day* is the two-digit day. We use this convention when working with date-based data as the directories are naturally in date order. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "│   ├── census\n",
    "│   └── nwc-wpc\n",
    "│       └── forecasts\n",
    "│           └── 2020\n",
    "│               ├── 01\n",
    "│               │   ├── 01\n",
    "│               │   ├── 02\n",
    "│               │   ├── 03\n",
    "│               │   ...\n",
    "│               │   ...\n",
    "│               │   ├── 30\n",
    "│               │   └── 31\n",
    "│               ├── 02\n",
    "│               │   ├── 01\n",
    "│               │   ├── 02\n",
    "│               │   ...\n",
    "│               │   ...\n",
    "│               │   ├── 28\n",
    "│               │   └── 29\n",
    "│               ├── 03\n",
    "│               ...\n",
    "│               ...\n",
    "│               ├── 11\n",
    "│               └── 12\n",
    "│                   ├── 01\n",
    "│                   ├── 02\n",
    "│                   ...\n",
    "│                   ...\n",
    "│                   ├── 29\n",
    "│                   ├── 30\n",
    "│                   └── 31\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 366\n"
     ]
    }
   ],
   "source": [
    "nwc_wpc_path = external_data_dir.joinpath('nwc-wpc')\n",
    "forecast_path = nwc_wpc_path.joinpath('forecasts')\n",
    "\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "def get_day_cal(target_year): \n",
    "    'take in target year, return list of days'\n",
    "    # First instantize a calender object and get a multi-dimensional array containing the months, weeks, and days for the given year.\n",
    "    # We use reduce and lambda to flatten the array to a single dimension - retaining order. \n",
    "    # Since the calendar can contain some entries from the year prior, or the year following, due to the weeks - so we filter them out.\n",
    "    # Finally, return the final list.\n",
    "    year_data = calendar.Calendar().yeardatescalendar(target_year, width=12)\n",
    "    month_list = reduce(lambda x,y: x+y, year_data)\n",
    "    week_list = reduce(lambda x,y: x+y, month_list)\n",
    "    day_list = reduce(lambda x,y: x+y, week_list)\n",
    "    day_list = [target_day for target_day in day_list if target_day.year == target_year]\n",
    "    return day_list\n",
    "\n",
    "def gen_date_paths(date_list, base_path, day_of_week = False):\n",
    "    '''Iterate through the date_list, then grab the parts of the datetime type and create a path object.\n",
    "    Next we add the path to a set containing directories, then return the set.\n",
    "    If day_of_week is True then it changes the day to the day of week instead'''\n",
    "    cal_date_dirs = set()\n",
    "    for date in date_list:\n",
    "        year, month, day = date.year, date.month, date.day\n",
    "        if day_of_week:\n",
    "            day = calendar.weekday(year, month, day)\n",
    "        date_tmp_path = base_path.joinpath(f'{year}/{month}/{day}')\n",
    "        cal_date_dirs.add(date_tmp_path)\n",
    "    return cal_date_dirs\n",
    "\n",
    "def make_date_paths(path_list):\n",
    "    'Attempts to make the directors for all paths in the list. Returns True if completed successfully, False if unsuccessful.'\n",
    "    for path_ in path_list:\n",
    "        try:\n",
    "            path_.mkdir(parents=True)\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "    return True\n",
    "curr_days = get_day_cal(current_year)\n",
    "forecast_dirs = gen_date_paths(curr_days, forecast_path)\n",
    "make_date_paths(forecast_dirs)\n",
    "\n",
    "next_yr_days = get_day_cal(current_year+1)\n",
    "leap_dirs = gen_date_paths(next_yr_days, forecast_path)\n",
    "make_date_paths(leap_dirs)\n",
    "# Should have 365 directories (366 if leap year)\n",
    "\n",
    "print(len(forecast_dirs), len(leap_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.2\n",
    "\n",
    "In the second part of the assignment, you will create the structure for the raw source data. We will use the following directory naming convention. \n",
    "\n",
    "```\n",
    "/data/raw/inventory/<location>/<year>/<month>/<day>/\n",
    "/data/raw/expenses/<location>/<year>/<month>/<day>/\n",
    "/data/raw/sales/<location>/<year>/<month>/<day>/<hour>/\n",
    "```\n",
    "For *location*, we will use the three-letter IATA code for the airport nearest to the location.  We will use the same year, month, and day convention from the previous example. For *hour*, we will use the two-digit hour value based on a 24-hour clock set to UTC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.2.a\n",
    "\n",
    "The following is an example of the directory structure for daily data dumps. \n",
    "\n",
    "```\n",
    "data\n",
    "├── external\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "    ├── expenses\n",
    "    ├── inventory\n",
    "    │   ├── bwi\n",
    "    │   ├── cmh\n",
    "    │   ├── den\n",
    "    │   ├── oma\n",
    "    │   │   └── 2020\n",
    "    │   │       ├── 01\n",
    "    │   │       │   ├── 01\n",
    "    │   │       │   ├── 02\n",
    "    │   │       │   ...    \n",
    "    │   │       │   └── 31\n",
    "    │   │       ├── 02\n",
    "    │   │       │   ├── 01\n",
    "    │   │       │   ...\n",
    "    │   │       │   └── 29\n",
    "    │   │       ├── 03\n",
    "    │   │       ... \n",
    "    │   │       ├── 11\n",
    "    │   │       └── 12\n",
    "    │   │           ├── 01\n",
    "    │   │           ├── 02\n",
    "    │   │           ...  \n",
    "    │   │           └── 31\n",
    "    │   └── sfo\n",
    "    └── sales\n",
    "```\n",
    "\n",
    "Create and add the paths for these data sets. Verify that you have added the paths correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory_dirs = set()\n",
    "inventory_path = raw_data_dir.joinpath('inventory')\n",
    "locations = ['bwi', 'cmh', 'den', 'oma', 'sfo']\n",
    "inv_paths = [inventory_path.joinpath(loc) for loc in locations]\n",
    "# TODO: Create and add the paths for this data set\n",
    "for loc_path in inv_paths:\n",
    "    temp_loc_set = gen_date_paths(curr_days, loc_path)\n",
    "    inventory_dirs |= temp_loc_set\n",
    "\n",
    "make_date_paths(inventory_dirs)\n",
    "\n",
    "# Should have 1825 directories (1830 if leap year)\n",
    "len(inventory_dirs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses_dirs = set()\n",
    "expense_path = raw_data_dir.joinpath('expenses')\n",
    "exp_paths = [expense_path.joinpath(loc) for loc in locations]\n",
    "# TODO: Create and add the paths for this data set\n",
    "\n",
    "for loc_path in exp_paths:\n",
    "    temp_loc_set = gen_date_paths(curr_days, loc_path)\n",
    "    expenses_dirs |= temp_loc_set\n",
    "\n",
    "make_date_paths(expenses_dirs)\n",
    "\n",
    "# Should have 1825 directories (1830 if leap year)\n",
    "len(expenses_dirs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.2.b\n",
    "\n",
    "Finally, create the paths for the hourly sales data. The following is an example of the directory structure for the sales data. \n",
    "\n",
    "```\n",
    "├── external\n",
    "├── interim\n",
    "├── processed\n",
    "└── raw\n",
    "    ├── expenses\n",
    "    ├── inventory\n",
    "    └── sales\n",
    "        ├── bwi\n",
    "        ├── cmh\n",
    "        ├── den\n",
    "        ├── oma\n",
    "        │   └── 2020\n",
    "        │       ├── 01\n",
    "        │       │   └── 01\n",
    "        │       │       ├── 00\n",
    "        │       │       ├── 01   \n",
    "        │       │       ├── 02\n",
    "        │       │       ...     \n",
    "        │       │       ├── 22\n",
    "        │       │       └── 23\n",
    "        │       ├── 02\n",
    "        │       ...\n",
    "        │       └── 12\n",
    "        └── sfo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_dirs = set()\n",
    "sales_path = raw_data_dir.joinpath('sales')\n",
    "sale_paths = [sales_path.joinpath(loc) for loc in locations]\n",
    "def date_add_hours(date_list, hour_list):\n",
    "    dates_plus_hours = set()\n",
    "    for date in date_list:\n",
    "        for hour in hour_list:\n",
    "            comb_date_hour = date.joinpath(str(hour))\n",
    "            dates_plus_hours.add(comb_date_hour)\n",
    "    return dates_plus_hours\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "\n",
    "for loc_path in sale_paths:\n",
    "    temp_loc_date_set = gen_date_paths(curr_days, loc_path)\n",
    "    temp_loc_dt_set = date_add_hours(temp_loc_date_set, range(24))\n",
    "    sales_dirs |= temp_loc_dt_set\n",
    "\n",
    "make_date_paths(sales_dirs)\n",
    "\n",
    "# Should have 43,800 directories (43,920 if leap year)\n",
    "len(sales_dirs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.a\n",
    "\n",
    "We have two choices for structuring our weekly data set. We can use the following naming convention where the date is based on the first day of the week. \n",
    "\n",
    "```\n",
    "/data/processed/modeling/<year>/<month>/<day>/\n",
    "```\n",
    "\n",
    "Otherwise, we could use a naming convention where *week* is the number of weeks it has been since the beginning of the year. \n",
    " \n",
    "```\n",
    "/data/processed/modeling/<year>/<week>/\n",
    "```\n",
    "\n",
    "We will use the first option for our naming convention. Python's *calendar* library has a function that determines the first day of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data_dirs = set()\n",
    "modeling_path = processed_data_dir.joinpath('modeling')\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "\n",
    "modeling_dirs= gen_date_paths(curr_days, modeling_path, day_of_week=True)\n",
    "modeling_data_dirs |= modeling_dirs\n",
    "make_date_paths(modeling_data_dirs)\n",
    "\n",
    "\n",
    "# Should have 52 directories\n",
    "\n",
    "#I just wanted to take a moment to point out there is a discrepency in the expected output vs the above request. If we do the first option we should have 12*7 directories (or 84)\n",
    "#The second option (# of weeks since start of year) then we would have the expected 52 directories.\n",
    "len(modeling_data_dirs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.b\n",
    "\n",
    "Next, create the monthly inventory requests using the following convention. \n",
    "\n",
    "```\n",
    "/data/processed/inventory/requests/<year>/<month>/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/processed/inventory/requests/2023/1'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/10'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/11'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/12'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/2'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/3'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/4'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/5'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/6'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/7'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/8'),\n",
       " WindowsPath('data/processed/inventory/requests/2023/9')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory_request_dirs = set()\n",
    "inventory_request_path = processed_data_dir.joinpath('inventory/requests')\n",
    "# TODO: Create and add the paths for this data set\n",
    "def gen_month_paths(year_list, base_path):\n",
    "    month_set = set()\n",
    "    for year in year_list:\n",
    "        year_month_list = set([base_path.joinpath(f'{year}/{i}') for i in range(1,13)])\n",
    "        month_set |= year_month_list\n",
    "    return month_set\n",
    "\n",
    "inventory_request_dirs |= gen_month_paths([current_year], inventory_request_path)\n",
    "make_date_paths(inventory_request_dirs)\n",
    " # Should output 12 directories\n",
    "sorted(list(inventory_request_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 5.3.c\n",
    "\n",
    "Finally, create the quarterly financial reports using the following convention. \n",
    "\n",
    "```\n",
    "`/data/processed/financials/quarterly/<year>/<quarter>/`\n",
    "```\n",
    "While it does not matter for this assignment, the following are the typical dates associated with financial quarters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/processed/financials/quarterly/2023/1'),\n",
       " WindowsPath('data/processed/financials/quarterly/2023/2'),\n",
       " WindowsPath('data/processed/financials/quarterly/2023/3'),\n",
       " WindowsPath('data/processed/financials/quarterly/2023/4')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_dirs = set()\n",
    "financial_path = processed_data_dir.joinpath('financials/quarterly')\n",
    "\n",
    "# TODO: Create and add the paths for this data set\n",
    "def gen_qtr_paths(year_list, base_path):\n",
    "    qtr_set = set()\n",
    "    for year in year_list:\n",
    "        year_qtr_list = set([base_path.joinpath(f'{year}/{i}') for i in range(1,5)])\n",
    "        qtr_set |= year_qtr_list\n",
    "    return qtr_set\n",
    "\n",
    "financials_dirs |= gen_qtr_paths([current_year], financial_path)\n",
    "# Should output four quarterly directories\n",
    "sorted(list(financials_dirs)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23b37b2c5ef3af92e6c5a1f41260f4d7d87b94b19a6a0241a9df183c040122f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
